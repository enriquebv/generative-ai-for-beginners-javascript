{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Prompt Engineering\n",
    "Prompt engineering is the process of designing and optimizing prompts for natural language processing tasks. It involves selecting the right prompts, tuning their parameters, and evaluating their performance. Prompt engineering is crucial for achieving high accuracy and efficiency in NLP models. In this section, we will explore the basics of prompt engineering using the OpenAI models for exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Tokenization\n",
    "Explore Tokenization using tiktoken, an open-source fast tokenizer from OpenAI\n",
    "See [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb) for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"\\n\",             \"J\",        \"upiter\",     \" is\",\n",
      "  \" the\",           \" fifth\",   \" planet\",    \" from\",\n",
      "  \" the\",           \" Sun\",     \" and\",       \" the\",\n",
      "  \" largest\",       \" in\",      \" the\",       \" Solar\",\n",
      "  \" System\",        \".\",        \" It\",        \" is\",\n",
      "  \" a\",             \" gas\",     \" giant\",     \" with\",\n",
      "  \" a\",             \" mass\",    \" one\",       \"-th\",\n",
      "  \"ousand\",         \"th\",       \" that\",      \" of\",\n",
      "  \" the\",           \" Sun\",     \",\",          \" but\",\n",
      "  \" two\",           \"-and\",     \"-a\",         \"-half\",\n",
      "  \" times\",         \" that\",    \" of\",        \" all\",\n",
      "  \" the\",           \" other\",   \" planets\",   \" in\",\n",
      "  \" the\",           \" Solar\",   \" System\",    \" combined\",\n",
      "  \".\",              \" Jupiter\", \" is\",        \" one\",\n",
      "  \" of\",            \" the\",     \" brightest\", \" objects\",\n",
      "  \" visible\",       \" to\",      \" the\",       \" naked\",\n",
      "  \" eye\",           \" in\",      \" the\",       \" night\",\n",
      "  \" sky\",           \",\",        \" and\",       \" has\",\n",
      "  \" been\",          \" known\",   \" to\",        \" ancient\",\n",
      "  \" civilizations\", \" since\",   \" before\",    \" recorded\",\n",
      "  \" history\",       \".\",        \" It\",        \" is\",\n",
      "  \" named\",         \" after\",   \" the\",       \" Roman\",\n",
      "  \" god\",           \" Jupiter\", \".[\",         \"19\",\n",
      "  \"]\",              \" When\",    \" viewed\",    \" from\",\n",
      "  \" Earth\",         \",\",        \" Jupiter\",   \" can\",\n",
      "  ... 35 more items\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken from 'npm:tiktoken'\n",
    "\n",
    "const text = `\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "`\n",
    "\n",
    "const encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "const tokens = encoding.encode(text)\n",
    "\n",
    "const decoded = []\n",
    "for (const token of tokens) {\n",
    "  const tokenBuffer = encoding.decode_single_token_bytes(token)\n",
    "  decoded.push(new TextDecoder().decode(tokenBuffer))\n",
    "}\n",
    "\n",
    "console.log(decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Validate OpenAI API Key Setup\n",
    "\n",
    "Run the code below to verify that your OpenAI endpoint is set up correctly. The code just tries a simple basic prompt and validates the completion. Input `oh say can you see` should complete along the lines of `by the dawn's early light..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by the dawn's early light\n"
     ]
    }
   ],
   "source": [
    "import { OpenAI } from 'https://deno.land/x/openai@1.4.3/mod.ts'\n",
    "\n",
    "const openai = new OpenAI(Deno.env.get('OPENAI_API_KEY') as string)\n",
    "\n",
    "async function getCompletion(prompt: string, model = 'gpt-3.5-turbo') {\n",
    "  const response = await openai.createChatCompletion({\n",
    "    model,\n",
    "    messages: [{ role: 'user', content: prompt }],\n",
    "    temperature: 0,\n",
    "    maxTokens: 1024,\n",
    "  })\n",
    "\n",
    "  return response.choices[0].message.content\n",
    "}\n",
    "\n",
    "const text = 'oh say can you see'\n",
    "const result = await getCompletion(text)\n",
    "\n",
    "console.log(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Hallucinations\n",
    "Explore what happens when you ask the LLM to return completions for a prompt about a topic that may not exist, or about topics that it may not know about because it was outside it's pre-trained dataset (more recent). See how the response changes if you try a different prompt, or a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Martian War of 2076 - A Lesson in Critical Thinking and Problem Solving\n",
      "\n",
      "Grade Level: High School (9th-12th grade)\n",
      "\n",
      "Objective:\n",
      "1. Students will analyze the Martian War of 2076, exploring its causes, consequences, and potential solutions.\n",
      "2. Students will develop critical thinking and problem-solving skills by evaluating the decisions made during the war and proposing alternative strategies.\n",
      "3. Students will engage in collaborative discussions, research, and presentation skills to communicate their findings effectively.\n",
      "\n",
      "Materials:\n",
      "1. Access to the internet and library resources\n",
      "2. Computers or tablets for research\n",
      "3. Whiteboard or blackboard\n",
      "4. Markers or chalk\n",
      "5. Handouts with guiding questions (optional)\n",
      "\n",
      "Procedure:\n",
      "\n",
      "Introduction (10 minutes):\n",
      "1. Begin the lesson by asking students if they have heard of the Martian War of 2076. Briefly explain that it was a fictional event portrayed in various science fiction works.\n",
      "2. Engage students in a discussion about the importance of critical thinking and problem-solving skills in real-life scenarios, such as war or conflict situations.\n",
      "\n",
      "Activity 1: Understanding the Martian War (20 minutes):\n",
      "1. Divide the class into small groups of 3-4 students.\n",
      "2. Assign each group a specific science fiction work that depicts the Martian War of 2076 (e.g., a novel, movie, or video game).\n",
      "3. Instruct the groups to research and analyze their assigned work, focusing on the causes, consequences, and major events of the Martian War.\n",
      "4. Encourage students to take notes and discuss their findings within their groups.\n",
      "\n",
      "Activity 2: Evaluating Decisions (25 minutes):\n",
      "1. Bring the class back together and facilitate a whole-class discussion.\n",
      "2. Ask each group to share their findings, highlighting the decisions made by the characters or factions involved in the Martian War.\n",
      "3. Encourage students to critically evaluate these decisions, considering their effectiveness, ethical implications, and potential alternatives.\n",
      "4. Write down key points on the whiteboard or blackboard for reference.\n",
      "\n",
      "Activity 3: Proposing Alternative Strategies (25 minutes):\n",
      "1. Divide the class into new groups, ensuring that each group has representation from the different initial groups.\n",
      "2. Instruct the groups to brainstorm and propose alternative strategies that could have been employed during the Martian War to achieve a more favorable outcome.\n",
      "3. Encourage students to consider diplomatic, technological, or military approaches, and to support their proposals with logical reasoning and evidence.\n",
      "4. Provide guidance and support as needed while students work on their proposals.\n",
      "\n",
      "Activity 4: Presentation and Discussion (20 minutes):\n",
      "1. Have each group present their alternative strategies to the class.\n",
      "2. Encourage the class to engage in a respectful and constructive discussion, asking questions and providing feedback on the proposed strategies.\n",
      "3. Facilitate the discussion by asking guiding questions, such as:\n",
      "   - What are the strengths and weaknesses of each proposed strategy?\n",
      "   - How might these strategies have affected the outcome of the Martian War?\n",
      "   - Are there any ethical concerns or unintended consequences associated with the proposed strategies?\n",
      "\n",
      "Conclusion (10 minutes):\n",
      "1. Summarize the key points discussed during the lesson, emphasizing the importance of critical thinking and problem-solving skills in real-life scenarios.\n",
      "2. Encourage students to apply these skills to other areas of their lives, such as personal decision-making or global issues.\n",
      "3. Conclude the lesson by highlighting the value of exploring fictional scenarios to develop a deeper understanding of complex problems.\n",
      "\n",
      "Note: This lesson plan is based on a fictional event and should be presented as such. It is essential to emphasize that the Martian War of 2076 is not a real historical event.\n"
     ]
    }
   ],
   "source": [
    "const text = 'generate a lesson plan on the Martian War of 2076.'\n",
    "const result = await getCompletion(text)\n",
    "\n",
    "console.log(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Instruction Based \n",
    "Use the \"text\" variable to set the primary content \n",
    "and the \"prompt\" variable to provide an instruction related to that primary content.\n",
    "\n",
    "Here we ask the model to summarize the text for a second-grade student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupiter is a really big planet that is far away from the Sun. It is made mostly of gas and is even bigger than all the other planets combined! People have known about Jupiter for a really long time because it is very bright in the sky at night. It is named after a god from ancient Rome. Sometimes, Jupiter is so bright that it can even make shadows on Earth. It is usually the third-brightest thing we can see in the sky, after the Moon and Venus.\n"
     ]
    }
   ],
   "source": [
    "const text = `\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "`\n",
    "\n",
    "const prompt = `\n",
    "Summarize content you are provided with a for a second-grade student.\n",
    "${text}\n",
    "`\n",
    "\n",
    "const result = await getCompletion(prompt)\n",
    "console.log(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Complex Prompt \n",
    "Try a request that has system, user and assistant messages \n",
    "System sets assistant context\n",
    "User & Assistant messages provide multi-turn conversation context\n",
    "\n",
    "Note how the assistant personality is set to \"sarcastic\" in the system context. \n",
    "Try using a different personality context. Or try a different series of input/output messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, they really mixed things up this year. The World Series was played at the prestigious Globe Life Field in Arlington, Texas. A fan-less ballpark, because nothing screams excitement like the sound of silence.\n"
     ]
    }
   ],
   "source": [
    "const result = await openai.createChatCompletion({\n",
    "    model: 'gpt-3.5-turbo',\n",
    "    messages: [\n",
    "      { role: 'system', content: 'You are a sarcastic assistant.' },\n",
    "      { role: 'user', content: 'Who won the world series in 2020?' },\n",
    "      { role: 'assistant', content: 'Who do you think won? The Los Angeles Dodgers of course.' },\n",
    "      { role: 'user', content: 'Where was it played?' },\n",
    "    ],\n",
    "  })\n",
    "  \n",
    "console.log(result.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Explore Your Intuition\n",
    "The above examples give you patterns that you can use to create new prompts (simple, complex, instruction etc.) - try creating other exercises to explore some of the other ideas we've talked about like examples, cues and more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.2.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
